{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyiqa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iimSuYpQa_kI",
        "outputId": "1deb6d9a-6920-4e72-ac97-8f5d237dee2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyiqa\n",
            "  Downloading pyiqa-0.1.14.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting accelerate<=1.1.0 (from pyiqa)\n",
            "  Downloading accelerate-1.1.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting addict (from pyiqa)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from pyiqa) (4.0.0)\n",
            "Collecting bitsandbytes (from pyiqa)\n",
            "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from pyiqa) (0.8.1)\n",
            "Collecting facexlib (from pyiqa)\n",
            "  Downloading facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from pyiqa) (1.0.0)\n",
            "Collecting icecream (from pyiqa)\n",
            "  Downloading icecream-2.1.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting lmdb (from pyiqa)\n",
            "  Downloading lmdb-1.7.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pyiqa) (2.0.2)\n",
            "Collecting openai-clip (from pyiqa)\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from pyiqa) (4.12.0.88)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from pyiqa) (2.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from pyiqa) (11.3.0)\n",
            "Collecting pre-commit (from pyiqa)\n",
            "  Downloading pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from pyiqa) (8.4.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from pyiqa) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pyiqa) (2.32.4)\n",
            "Requirement already satisfied: ruff in /usr/local/lib/python3.12/dist-packages (from pyiqa) (0.14.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from pyiqa) (0.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pyiqa) (1.16.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from pyiqa) (0.2.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from pyiqa) (2.19.0)\n",
            "Requirement already satisfied: timm>=0.8 in /usr/local/lib/python3.12/dist-packages (from pyiqa) (1.0.22)\n",
            "Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.12/dist-packages (from pyiqa) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.13 in /usr/local/lib/python3.12/dist-packages (from pyiqa) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pyiqa) (4.67.1)\n",
            "Collecting transformers==4.37.2 (from pyiqa)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yapf (from pyiqa)\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2->pyiqa) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2->pyiqa) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2->pyiqa) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2->pyiqa) (2025.11.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2->pyiqa)\n",
            "  Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.37.2->pyiqa) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.1.0->pyiqa) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.12->pyiqa) (3.5.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->pyiqa) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->pyiqa) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->pyiqa) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->pyiqa) (0.70.16)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pyiqa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pyiqa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pyiqa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pyiqa) (2025.11.12)\n",
            "Collecting filterpy (from facexlib->pyiqa)\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from facexlib->pyiqa) (0.60.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from facexlib->pyiqa) (4.12.0.88)\n",
            "Collecting colorama>=0.3.9 (from icecream->pyiqa)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from icecream->pyiqa) (2.19.2)\n",
            "Collecting executing>=2.1.0 (from icecream->pyiqa)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream->pyiqa)\n",
            "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting ftfy (from openai-clip->pyiqa)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->pyiqa) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->pyiqa) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->pyiqa) (2025.2)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->pyiqa)\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->pyiqa)\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->pyiqa)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->pyiqa)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->pyiqa) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->pyiqa) (1.6.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pyiqa) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pyiqa) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->pyiqa) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->pyiqa) (3.1.4)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.12/dist-packages (from yapf->pyiqa) (4.5.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (3.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->pyiqa) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.12->pyiqa) (1.3.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->pyiqa)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->pyiqa) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from filterpy->facexlib->pyiqa) (3.10.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->openai-clip->pyiqa) (0.2.14)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->facexlib->pyiqa) (0.43.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->pyiqa) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->facexlib->pyiqa) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->facexlib->pyiqa) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->facexlib->pyiqa) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->facexlib->pyiqa) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->filterpy->facexlib->pyiqa) (3.2.5)\n",
            "Downloading pyiqa-0.1.14.1-py3-none-any.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.2/276.2 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.1.0-py3-none-any.whl (333 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading facexlib-0.3.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading icecream-2.1.8-py3-none-any.whl (15 kB)\n",
            "Downloading lmdb-1.7.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading tokenizers-0.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-clip, filterpy\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368605 sha256=a22d4c799f84a68f9b11b80783ca460f11af800b951918be4e4e4ef0b5926b95\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/49/bc/c2342e8e14878210ba4825cf314a53f2570f6fb18b91fce3cf\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110460 sha256=7bbcf43a4feeb7f75728fbe682849a57f7fdd3e24c9ed8e11e7449c47b22c22f\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\n",
            "Successfully built openai-clip filterpy\n",
            "Installing collected packages: lmdb, distlib, addict, yapf, virtualenv, nodeenv, identify, ftfy, executing, colorama, cfgv, asttokens, pre-commit, openai-clip, icecream, tokenizers, filterpy, transformers, bitsandbytes, accelerate, facexlib, pyiqa\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.1.0 addict-2.4.0 asttokens-3.0.1 bitsandbytes-0.48.2 cfgv-3.5.0 colorama-0.4.6 distlib-0.4.0 executing-2.2.1 facexlib-0.3.0 filterpy-1.4.5 ftfy-6.3.1 icecream-2.1.8 identify-2.6.15 lmdb-1.7.5 nodeenv-1.9.1 openai-clip-1.0.1 pre-commit-4.5.0 pyiqa-0.1.14.1 tokenizers-0.15.2 transformers-4.37.2 virtualenv-20.35.4 yapf-0.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkG3I7Zc16jX",
        "outputId": "197c20f1-cd42-498d-afa8-ada7d13da91b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Working directory ready: /content/drive/My Drive/ECE253_Project\n"
          ]
        }
      ],
      "source": [
        "# Part 0: Environment Setup & Drive Mounting\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the project root directory in your Drive\n",
        "PROJECT_ROOT = \"/content/drive/My Drive/ECE253_Project\"\n",
        "\n",
        "# 3. Define sub-directories for organized storage\n",
        "DIRS = {\n",
        "    \"GT\": os.path.join(PROJECT_ROOT, \"1_GroundTruth\"),      # Folder for Sharp images\n",
        "    \"BLUR\": os.path.join(PROJECT_ROOT, \"2_InputBlur\"),      # Folder for Blurred images\n",
        "    \"RL_OUT\": os.path.join(PROJECT_ROOT, \"3_Output_RL\"),    # Folder for RL results\n",
        "    \"NAF_OUT\": os.path.join(PROJECT_ROOT, \"4_Output_NAFNet\"), # Folder for NAFNet results\n",
        "    \"NAF_FT_OUT\": os.path.join(PROJECT_ROOT, \"5_Output_NAFNet_FineTuned\"),\n",
        "    \"METRICS\": os.path.join(PROJECT_ROOT, \"Metrics\")        # Folder for CSV files\n",
        "}\n",
        "\n",
        "# 4. Create directories if they don't exist\n",
        "for k, v in DIRS.items():\n",
        "    os.makedirs(v, exist_ok=True)\n",
        "\n",
        "print(f\"✅ Working directory ready: {PROJECT_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.1: NAFNet Architecture Definition\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- Layer Normalization ---\n",
        "class LayerNormFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, weight, bias, eps):\n",
        "        ctx.eps = eps\n",
        "        N, C, H, W = x.size()\n",
        "        mu = x.mean(1, keepdim=True)\n",
        "        var = (x - mu).pow(2).mean(1, keepdim=True)\n",
        "        y = (x - mu) / (var + eps).sqrt()\n",
        "        ctx.save_for_backward(y, var, weight)\n",
        "        y = weight.view(1, C, 1, 1) * y + bias.view(1, C, 1, 1)\n",
        "        return y\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        eps = ctx.eps\n",
        "        N, C, H, W = grad_output.size()\n",
        "        y, var, weight = ctx.saved_tensors\n",
        "        g = grad_output * weight.view(1, C, 1, 1)\n",
        "        mean_g = g.mean(dim=1, keepdim=True)\n",
        "        mean_gy = (g * y).mean(dim=1, keepdim=True)\n",
        "        gx = 1. / torch.sqrt(var + eps) * (g - y * mean_gy - mean_g)\n",
        "        return gx, (grad_output * y).sum(dim=3).sum(dim=2).sum(dim=0), grad_output.sum(dim=3).sum(dim=2).sum(dim=0), None\n",
        "\n",
        "class LayerNorm2d(nn.Module):\n",
        "    def __init__(self, channels, eps=1e-6):\n",
        "        super(LayerNorm2d, self).__init__()\n",
        "        self.register_parameter('weight', nn.Parameter(torch.ones(channels)))\n",
        "        self.register_parameter('bias', nn.Parameter(torch.zeros(channels)))\n",
        "        self.eps = eps\n",
        "    def forward(self, x):\n",
        "        return LayerNormFunction.apply(x, self.weight, self.bias, self.eps)\n",
        "\n",
        "# --- SimpleGate ---\n",
        "class SimpleGate(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x1, x2 = x.chunk(2, dim=1)\n",
        "        return x1 * x2\n",
        "\n",
        "# --- NAFBlock ---\n",
        "class NAFBlock(nn.Module):\n",
        "    def __init__(self, c, DW_Expand=2, FFN_Expand=2, drop_out_rate=0.):\n",
        "        super().__init__()\n",
        "        dw_channel = c * DW_Expand\n",
        "        self.conv1 = nn.Conv2d(in_channels=c, out_channels=dw_channel, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels=dw_channel, out_channels=dw_channel, kernel_size=3, padding=1, stride=1, groups=dw_channel, bias=True)\n",
        "        self.conv3 = nn.Conv2d(in_channels=dw_channel // 2, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
        "        self.sca = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels=dw_channel // 2, out_channels=dw_channel // 2, kernel_size=1, padding=0, stride=1, groups=1, bias=True),\n",
        "        )\n",
        "        self.conv4 = nn.Conv2d(in_channels=c, out_channels=c * FFN_Expand, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
        "        self.conv5 = nn.Conv2d(in_channels=c * FFN_Expand // 2, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1, bias=True)\n",
        "        self.norm1 = LayerNorm2d(c)\n",
        "        self.norm2 = LayerNorm2d(c)\n",
        "        self.dropout1 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()\n",
        "        self.dropout2 = nn.Dropout(drop_out_rate) if drop_out_rate > 0. else nn.Identity()\n",
        "        self.beta = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)\n",
        "        self.gamma = nn.Parameter(torch.zeros((1, c, 1, 1)), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = SimpleGate()(x)\n",
        "        x = x * self.sca(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.dropout1(x)\n",
        "        y = inp + x * self.beta\n",
        "        x = self.norm2(y)\n",
        "        x = self.conv4(x)\n",
        "        x = SimpleGate()(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.dropout2(x)\n",
        "        return y + x * self.gamma\n",
        "\n",
        "# --- NAFNet ---\n",
        "class NAFNet(nn.Module):\n",
        "    def __init__(self, img_channel=3, width=16, middle_blk_num=1, enc_blk_nums=[], dec_blk_nums=[]):\n",
        "        super().__init__()\n",
        "        self.intro = nn.Conv2d(in_channels=img_channel, out_channels=width, kernel_size=3, padding=1, stride=1, groups=1, bias=True)\n",
        "        self.ending = nn.Conv2d(in_channels=width, out_channels=img_channel, kernel_size=3, padding=1, stride=1, groups=1, bias=True)\n",
        "        self.encoders = nn.ModuleList()\n",
        "        self.decoders = nn.ModuleList()\n",
        "        self.middle_blks = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        chan = width\n",
        "        for num in enc_blk_nums:\n",
        "            self.encoders.append(nn.Sequential(*[NAFBlock(chan) for _ in range(num)]))\n",
        "            self.downs.append(nn.Conv2d(chan, 2*chan, 2, 2))\n",
        "            chan = chan * 2\n",
        "        self.middle_blks = nn.Sequential(*[NAFBlock(chan) for _ in range(middle_blk_num)])\n",
        "        for num in dec_blk_nums:\n",
        "            self.ups.append(nn.Sequential(nn.Conv2d(chan, chan * 2, 1, bias=False), nn.PixelShuffle(2)))\n",
        "            chan = chan // 2\n",
        "            self.decoders.append(nn.Sequential(*[NAFBlock(chan) for _ in range(num)]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = x\n",
        "        x = self.intro(x)\n",
        "        encs = []\n",
        "        for encoder, down in zip(self.encoders, self.downs):\n",
        "            x = encoder(x)\n",
        "            encs.append(x)\n",
        "            x = down(x)\n",
        "        x = self.middle_blks(x)\n",
        "        for decoder, up, enc_skip in zip(self.decoders, self.ups, encs[::-1]):\n",
        "            x = up(x)\n",
        "            x = x + enc_skip\n",
        "            x = decoder(x)\n",
        "        x = self.ending(x)\n",
        "        return x + inp\n",
        "\n",
        "print(\"✅ Cell 3.1: NAFNet architecture defined successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiofVhej2J1c",
        "outputId": "0ffb21e8-4db6-4803-8270-0e9e75f2d6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 3.1: NAFNet architecture defined successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.2: Load Pre-trained Weights\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# 1. Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\">>> Running on device: {device}\")\n",
        "\n",
        "# 2. Initialize Model (Width=32 configuration for GoPro)\n",
        "model_naf = NAFNet(img_channel=3, width=32, middle_blk_num=1,\n",
        "                   enc_blk_nums=[1, 1, 1, 28], dec_blk_nums=[1, 1, 1, 1])\n",
        "\n",
        "# 3. Download and Load Weights\n",
        "weight_path = \"NAFNet-GoPro-width32.pth\"\n",
        "weight_url = \"https://huggingface.co/nyanko7/nafnet-models/resolve/main/NAFNet-GoPro-width32.pth\"\n",
        "\n",
        "if not os.path.exists(weight_path):\n",
        "    print(\">>> Downloading pre-trained weights from HuggingFace...\")\n",
        "    os.system(f\"curl -L -o {weight_path} {weight_url}\")\n",
        "\n",
        "print(\">>> Loading weights into model...\")\n",
        "try:\n",
        "    checkpoint = torch.load(weight_path, map_location=device)\n",
        "    param_dict = checkpoint['params'] if 'params' in checkpoint else checkpoint\n",
        "    model_naf.load_state_dict(param_dict, strict=False)\n",
        "    model_naf.to(device)\n",
        "    # Set to Eval mode immediately since we are not training\n",
        "    model_naf.eval()\n",
        "    print(\"✅ Cell 3.2: Model loaded and set to Eval mode.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading weights: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHowwp7R263z",
        "outputId": "60f38c4f-07c0-4706-ff3c-20c716ff7c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Running on device: cuda\n",
            ">>> Downloading pre-trained weights from HuggingFace...\n",
            ">>> Loading weights into model...\n",
            "✅ Cell 3.2: Model loaded and set to Eval mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.3: NAFNet Inference - Updated with NIQE & No-GT Support\n",
        "# ==============================================================\n",
        "import pandas as pd\n",
        "from skimage import metrics\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch\n",
        "import pyiqa\n",
        "\n",
        "# 1. Initialize NIQE\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\">>> Loading NIQE metric...\")\n",
        "try:\n",
        "    niqe_metric = pyiqa.create_metric('niqe', device=device)\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Warning: Could not load NIQE: {e}\")\n",
        "    niqe_metric = None\n",
        "\n",
        "# Ensure model is in eval mode\n",
        "model_naf.eval()\n",
        "results_naf = []\n",
        "\n",
        "files = sorted(os.listdir(DIRS[\"BLUR\"]))\n",
        "print(f\">>> Starting NAFNet Inference on {len(files)} images...\")\n",
        "\n",
        "for f in tqdm(files, desc=\"NAFNet Inference\"):\n",
        "    # Paths\n",
        "    path_blur = os.path.join(DIRS[\"BLUR\"], f)\n",
        "    path_gt = os.path.join(DIRS[\"GT\"], f)\n",
        "    # Output path (using NAF_OUT as default)\n",
        "    path_out = os.path.join(DIRS[\"NAF_OUT\"], f)\n",
        "\n",
        "    # Check GT\n",
        "    has_gt = os.path.exists(path_gt)\n",
        "\n",
        "    # Read Image\n",
        "    img_blur_orig = cv2.imread(path_blur)\n",
        "    if img_blur_orig is None: continue # Skip corrupt files\n",
        "    img_blur_orig = cv2.cvtColor(img_blur_orig, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Preprocess\n",
        "    img_tensor = torch.from_numpy(img_blur_orig.astype(np.float32)/255.0)\n",
        "    img_tensor = img_tensor.permute(2,0,1).unsqueeze(0).to(device)\n",
        "\n",
        "    # Inference\n",
        "    with torch.no_grad():\n",
        "        # Handle Padding (NAFNet requires input to be multiple of 32)\n",
        "        _, _, h, w = img_tensor.shape\n",
        "        h_n = (h // 32) * 32\n",
        "        w_n = (w // 32) * 32\n",
        "        inp = img_tensor[:, :, :h_n, :w_n]\n",
        "\n",
        "        output = model_naf(inp)\n",
        "\n",
        "    # Post-process\n",
        "    out_img = output.squeeze().cpu().permute(1,2,0).numpy()\n",
        "    out_img = np.clip(out_img, 0, 1)\n",
        "    out_uint8 = (out_img * 255.0).astype(np.uint8)\n",
        "\n",
        "    # Save Result\n",
        "    cv2.imwrite(path_out, cv2.cvtColor(out_uint8, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    # --- Metrics Calculation ---\n",
        "    row = {\"Image\": f, \"Method\": \"NAFNet\", \"Has_GT\": has_gt}\n",
        "\n",
        "    # 1. NIQE (No-Reference)\n",
        "    if niqe_metric:\n",
        "        out_tensor = torch.from_numpy(out_uint8).permute(2,0,1).unsqueeze(0).float() / 255.0\n",
        "        row[\"NIQE\"] = niqe_metric(out_tensor.to(device)).item()\n",
        "    else:\n",
        "        row[\"NIQE\"] = None\n",
        "\n",
        "    # 2. PSNR/SSIM (Full-Reference)\n",
        "    if has_gt:\n",
        "        img_gt = cv2.cvtColor(cv2.imread(path_gt), cv2.COLOR_BGR2RGB)\n",
        "        # Important: Crop GT to match NAFNet output (due to padding)\n",
        "        gt_crop = img_gt[:h_n, :w_n, :]\n",
        "\n",
        "        row[\"PSNR\"] = metrics.peak_signal_noise_ratio(gt_crop, out_uint8)\n",
        "        row[\"SSIM\"] = metrics.structural_similarity(gt_crop, out_uint8, channel_axis=2, win_size=3)\n",
        "    else:\n",
        "        row[\"PSNR\"] = None\n",
        "        row[\"SSIM\"] = None\n",
        "\n",
        "    results_naf.append(row)\n",
        "\n",
        "# Save Metrics\n",
        "csv_path = os.path.join(DIRS[\"METRICS\"], \"metrics_nafnet.csv\")\n",
        "pd.DataFrame(results_naf).to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"✅ Cell 3.3 Complete: Processed {len(files)} images.\")\n",
        "print(f\"✅ Metrics saved to {csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sy0391R4LxE",
        "outputId": "797d3456-ff5a-45e7-c12e-b5dbfb84948d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Loading NIQE metric...\n",
            "Downloading: \"https://huggingface.co/chaofengc/IQA-PyTorch-Weights/resolve/main/niqe_modelparameters.mat\" to /root/.cache/torch/hub/pyiqa/niqe_modelparameters.mat\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.15k/8.15k [00:00<00:00, 31.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Starting NAFNet Inference on 110 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "NAFNet Inference: 100%|██████████| 110/110 [03:36<00:00,  1.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cell 3.3 Complete: Processed 110 images.\n",
            "✅ Metrics saved to /content/drive/My Drive/ECE253_Project/Metrics/metrics_nafnet.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfWOGliVbMka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}